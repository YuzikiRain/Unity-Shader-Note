## 数学函数

### saturate(x)

截取到0~1，相当于`clamp(x, 0, 1)`

### clamp(v, min, max)

将v夹取到$[min, max]$区间

### smoothstep(float t1, float t2, float x)

```cpp
float smoothstep(float t1, float t2, float x) {
  // Scale, bias and saturate x to 0..1 range
  x = clamp((x - t1) / (t2 - t1), 0.0, 1.0); 
  // Evaluate polynomial
  return x * x * (3 - 2 * x);
}
```

### step (a, x)

``` glsl
step (a, x)
{
  if (x < a) 
  {
    return 0;
  }
  else
  {
    return 1;
  }
}
```

常用于优化`if else`或` if a ? b : c`等结构

``` glsl
return a < b ? c : d;
// 等价于
return a - b < 0 ? c : d;
// 等价于
half k = step(a, b);
return k * c + (1-k) * d;
```

### **ddx(propertyName)，ddy(propertyName)，fwidth(propertyName)**

ddx和ddy分别表示x、y方向上的在该像素上的微分

`fwidth = abs(ddx(p)) + abs(ddy(p))`

propertyName参数可传入`Position`、`Normal`、`Color`、`UV`等，分别用于计算该像素与相邻两个像素的这些属性的差值

用途：

- 由于像素距离足够小，通常认为可用于近似计算该点的积分（变化率）：`ratio = ddy(p) / ddx(p)`
- 计算`MipMapLevel`：[shader 中，fwidth 或者说 ddx/ddy 到底是什么意思？ - Alec的回答 - 知乎](https://www.zhihu.com/question/329521044/answer/1286662690)

参考：[An introduction to shader derivative functions | A Clockwork Berry](http://www.aclockworkberry.com/shader-derivative-functions/)

## 函数

### ComputeScreenPos

URP：`Core/Core.hlsl`

``` glsl
// TODO: A similar function should be already available in SRP lib on master. Use that instead
float4 ComputeScreenPos(float4 positionCS)
{
    float4 o = positionCS * 0.5f;
    o.xy = float2(o.x, o.y * _ProjectionParams.x) + o.w;
    o.zw = positionCS.zw;
    return o;
}
```

built-in：UnityCG.cginc

``` glsl
inline float4 ComputeNonStereoScreenPos(float4 pos) {
    float4 o = pos * 0.5f;
    o.xy = float2(o.x, o.y*_ProjectionParams.x) + o.w;
    o.zw = pos.zw;
    return o;
}

inline float4 ComputeScreenPos(float4 pos) {
    float4 o = ComputeNonStereoScreenPos(pos);
    #if defined(UNITY_SINGLE_PASS_STEREO)
    o.xy = TransformStereoScreenSpaceTex(o.xy, pos.w);
    #endif
    return o;
}
```

这里其实就是相当于加1，然后除以2，将范围为$[-w,w]$的xy分量映射到$[0,w]$

_ProjectionParams.x：1表示投影已上下翻转（以匹配类似 OpenGL 的投影坐标），-1表示它尚未翻转

该函数一般用于采样屏幕空间贴图（比如深度纹理）

 ``` glsl
 float4 screenPosition = ComputeScreenPos(positionCS);  // 范围为[0,w]
 tex2Dproj(_CameraDepthTexture, screenPosition);  // tex2Dproj会先将uv先除以w再进行采样，即使用范围为[0,1]的uv进行采样
 ```

也等同于以下操作

``` glsl
float4 screenPosition = ComputeScreenPos(positionCS);
tex2D(_CameraDepthTexture, float2(screenPosition.xy / screenPosition.w))
```

虽然的函数名字似乎意味着会直接得到屏幕空间中的位置，但并不是这样的，我们仍需在片元着色器中除以它的w分量来得到真正的视口空间中的位置。那么，为什么Unity不直接在ComputeScreenPos中为我们进行除以w分量的这个步骤呢？为什么还需要我们来进行这个除法？这是因为，如果Unity在顶点着色器中这么做的话，就会**破坏插值**的结果。

我们知道，从顶点着色器到片元着色器的过程实际会有一个插值的过程（如果你忘了的话，可以回顾2.3.6小节）。如果不在顶点着色器中进行这个除法，保留x、y和w分量，那么它们在插值后再进行这个除法，得到的和就是正确的（我们可以认为是除法抵消了插值的影响）。但如果我们直接在顶点着色器中进行这个除法，那么就需要对和直接进行插值，这样得到的插值结果就会不准确。原因是，我们不可以在投影空间中进行插值，因为这并不是一个线性空间，而插值往往是线性的

顶点着色器中将顶点位置变换到齐次裁剪坐标空间下，进行输出（用`SV_POSITION`关键字标记的变量表示顶点着色器的输出）后，再由硬件做透视除法

参考自《Unity shader入门精要》2.3.2章节

参考：

[Unity Shader中的ComputeScreenPos函数 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/145400372)

### LinearEyeDepth

将深度缓冲或深度纹理中的（非线性）深度值转换到观察空间下的（线性）深度值（即positionVS.z），结果取值范围为$[Near,Far]$。

为什么不是$[-Near,-Far]$？因为该函数还对Near和Far进行了取反：`Near *= -1`，`Far *= -1`

### Linear01Depth

等同于`LinearEyeDepth()/Far`，结果取值范围为$[0,1]$，0表示刚好在摄像机位置上（而不是近平面），1表示在远平面上。

### SampleSceneDepth

其实就是对`_CameraDepthTexture`采样的封装

`com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl`

``` glsl
#ifndef UNITY_DECLARE_DEPTH_TEXTURE_INCLUDED
#define UNITY_DECLARE_DEPTH_TEXTURE_INCLUDED
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

TEXTURE2D_X_FLOAT(_CameraDepthTexture);
SAMPLER(sampler_CameraDepthTexture);

float SampleSceneDepth(float2 uv)
{
    return SAMPLE_TEXTURE2D_X(_CameraDepthTexture, sampler_CameraDepthTexture, UnityStereoTransformScreenSpaceTex(uv)).r;
}

float LoadSceneDepth(uint2 uv)
{
    return LOAD_TEXTURE2D_X(_CameraDepthTexture, uv).r;
}
#endif
```

[Graphics/DeclareDepthTexture.hlsl at master · Unity-Technologies/Graphics (github.com)](https://github.com/Unity-Technologies/Graphics/blob/master/Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl)

### ComputeWorldSpacePosition

``` glsl
float3 ComputeWorldSpacePosition(float2 positionNDC, float deviceDepth, float4x4 invViewProjMatrix)
{
    float4 positionCS  = ComputeClipSpacePosition(positionNDC, deviceDepth);
    float4 hpositionWS = mul(invViewProjMatrix, positionCS);
    return hpositionWS.xyz / hpositionWS.w;
}
```

为什么从裁剪空间变换到世界空间不是先乘以裁剪空间的w再进行vp逆矩阵变换，而是先进行vp逆矩阵变换再除以世界空间的w？https://blog.csdn.net/yinfourever/article/details/120935179

